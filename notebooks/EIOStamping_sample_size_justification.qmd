---
title: "Sample Size Justification"
format:
  pdf:
    toc: true
    number-sections: true
---

```{r}
ref <- read.csv("reference_table_number_of_required_samples_for_confidence_reliability_claim.csv")
```

```{r}
samples_required_for_testing <- function(n_failures_accepted = c(0,1,2),
                                         total_number_of_tests = c(1, 3, 15),
                                         reliabilities = c(0.9,0.95,0.99),
                                         confidence = c(0.90, 0.95)){  
  
  # -------------------------------------------
  # n_failures_accepted: Number of failures to be tolerated to obtain desired confidence/reliability
  # total_number_of_tests: Total number of evaluations to be performed...used for multiplicity correction
  # reliabilities: vector of desired reliability claims
  # confidence: vector of desired confidence claims
  # -------------------------------------------
  
  
  require(tidyverse)
  require(dplyr)
  
  get_number_of_samples_to_test <- function(n_builds_per_lot = 1000,
                                            n_lots = 3,
                                            reliability = 0.99,
                                            prior_shape1 = 199,
                                            prior_shape2 = 1,
                                            confidence = 0.95,
                                            n_failures_tolerated = 0,
                                            bonferroni_correction_factor = 1, 
                                            iter_value = 1E-6, 
                                            standardize_to_2_obs = TRUE){
    

    total <- prior_shape1 + prior_shape2
    if(standardize_to_2_obs){
      prior_shape1 <- 2*prior_shape1 / total
      prior_shape2 <- 2*prior_shape2 / total
    }
    alpha <- 1 - confidence
    posterior_density <- function(n){
      return(pbeta(reliability, 
                   shape1 = prior_shape1 + n - n_failures_tolerated, 
                   shape2 = n_failures_tolerated + prior_shape2, 
                   lower.tail = FALSE))
    }
    
    out_n <- seq_along(1:n_builds_per_lot)
    out_post <- sapply(out_n, posterior_density)
    return(out_n[out_post >= (1 - alpha/bonferroni_correction_factor)][1])
  }
  
  grid <- expand.grid(n_failures_accepted, total_number_of_tests, reliabilities, 1, confidence)
  colnames(grid) <- c("n_failures_accepted", "total_number_of_tests", "reliability", "prior_successes", "confidence")

  samples_required <- apply(grid, 1, function(i){
    get_number_of_samples_to_test(prior_shape1 = as.numeric(i[4]), 
                                  prior_shape2 = 1,
                                  n_builds_per_lot = 1000, 
                                  reliability = as.numeric(i[3]), 
                                  confidence = i[5], 
                                  n_failures_tolerated = as.numeric(i[1]),
                                  n_lots = 3,
                                  bonferroni_correction_factor = as.numeric(i[2]))
  })
  
  grid <- grid %>% mutate(samples_required = samples_required) %>%
    select(-prior_successes) %>%
    arrange(confidence, reliability, n_failures_accepted)
  return(grid)  
}

# run the function
samples_required_for_testing()
```

```{r}
# 1. number failures, 2. total number test 3. Confidence 4. Reliability
samples_required_for_testing(0, 3, .95, .95)
```

```{r}
library(dplyr)
# Using the CSV file

ref %>% filter(Total.Number.of.Tests == 3)

# How much are we allowing to fail? 
```

10 wells being sampled on 5 plates == 1 TEST
if you allow 1 failure, 1/50 wells 

3 plates per deck, total of 72; 
Sample size * Well Numbers (48)

